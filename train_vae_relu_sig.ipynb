{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_vae (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST.traindata(Float32)\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, decoder, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), decoder = cpu(decoder)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "\n",
    "    decoder = Chain(\n",
    "        Dense(20, 500, relu, bias = false),\n",
    "        Dense(500, 500, relu, bias = false),\n",
    "        Dense(500, 784, sigmoid, bias = false)\n",
    "    )\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, decoder, x, β, λ)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = decoder(z)\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = -sum(logitbinarycrossentropy.(x̂, x)) / batch_size\n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) / batch_size\n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, decoder))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = logp_x_z - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "    return -elbo + Flux.mse(x̂, x) + reg\n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, decoder)\n",
    "\n",
    "    for epoch_num = 1:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        progress_tracker = Progress(length(dataloader), 1, \"Training epoch $epoch_num: \")\n",
    "        ProgressMeter.ijulia_behavior(:append)\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, decoder, x_batch, β, λ)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "            next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        end\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, decoder, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Matrix{Float32}, Vector{Int64}}, Random._GLOBAL_RNG}((Float32[1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [5, 0, 4, 1, 9, 2, 1, 3, 1, 4  …  9, 2, 9, 5, 1, 8, 3, 5, 6, 8]), 64, 60000, false, 59937, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  59991, 59992, 59993, 59994, 59995, 59996, 59997, 59998, 59999, 60000], true, Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "num_epochs = 20\n",
    "save_dir = \"result\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b060f6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Chain(Chain(Dense(784, 500, relu), Dense(500, 500, relu)), Dense(500, 20)), Chain(Chain(Dense(784, 500, relu), Dense(500, 500, relu)), Dense(500, 20)), Chain(Dense(20, 500, relu; bias=false), Dense(500, 500, relu; bias=false), Dense(500, 784, relu; bias=false)))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_μ, encoder_logvar, decoder = create_vae()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1d009d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell. \n",
      "│  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`. \n",
      "│  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.\n",
      "└ @ ProgressMeter /project/def-mpf/bjoshi/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620\n",
      "\u001b[32mTraining epoch 20: 100%|████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[34m  loss:  157.72969\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    20        161.758\n",
      "Saving model...Done\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"result\"\n",
    "train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, ADAM(η), save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eab90f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux: chunk\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST.testdata(Float32)\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, decoder, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = decoder(z)\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 64\n",
    "    shuffle = true\n",
    "    num_images = 30\n",
    "    epoch_to_load = 20\n",
    "    # Load the model and test set loader\n",
    "    encoder_μ, encoder_logvar, decoder = load_model(\"result\", epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, \"result\", \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, x_batch)\n",
    "        save_to_images(x̂_batch, \"result\", \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAYlJREFUaAW9wbFuT3EABtDT+JJOIiyWTl7AYOcR2CWGkjCUrUaqq9HUYLKZajLzABKLZ+jI0jQRauhw06T993ev5Dsnx7qiLMqiLMqiLMqiLMqiLMqiLP7DmslvxMWiLMqiLBZac1qMibIoi7JY4JbTPhoXZVEWZTHTG3wzOcK6cVEWZVEWMz0zOcK6eaIsyqIsZrhkchvr5ouyKIuymOGvyRfLRFmURVkMumrywnJRFmVRFoN+mryyXJRFWZTFgEPne4APTjzCW6tFWZRFWQzYN7nhxFfccdo73MSW80VZlEVZDLhvcogn2HO2p9hyviiLsiiLmQ6w57Qr+GVMlEVZlMVC1/AdG/iDGBNlURZlscB1HJh8NtmwWpRFWZTFAo9NPuGeyQ+rRVmURVkM2MGOyS52ne2y1aIsyqIsBrzEjosdu1iURVmUxaD3eOh8x8ZEWZRFWQzaxCZe47kTd7FvniiLsiiLmbaxbbkoi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Io+we4cCfu/aJezwAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(\"result/reconstruction-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAfpJREFUaAW9wUHI33MAB+Dnvz6tyOE9oR0mpzelXRel5t3k5CYHBxeW5aDktr0pacltia30njS3FyVRbyEXcthNTQ5OO7xLsSYRicPv8DvI//3+XvV5nvytK8qiLMqiLMqiLMqiLMqiLMrif9jDNm5gDw86WJRFWZTFIXyPt/Aubptcwo6DRVmURVks9B22sG9yBGfxmjFRFmVRFgt9jn2zN/GCcVEWZVEWC7yB183exlnLRFmURVkM+gO7uG1yDs8ilomyKIuyGPQprpls4LLDibIoi7IY9JHZkw4vyqIsymLAdeyabZv9ht9NNrCyXpRFWZTFgC/wi8lJ3G3yPl7FtyZX8Lz1oizKoiwGrMwexxE8gw/xq9mL2MQp/y3KoizKYsA9ZvfiPtw0OY37sYM/8bP1oizKoiwW+gw3cRcu4jR+wo4xURZlURYLbOIojuI9PGHyjnFRFmVRFgOumtyJbTyHR032ccm4KIuyKIsBL+ET/IAbeMzsPK5jhRM4ab0oi7IoiwGP4BT2cB4bOI6n8SVWJhdxzHpRFmVRFoNewVe4hoewwl9mx7DlYFEWZVEWgx7GB3gKt/zbx7jDwaIsyqIsFjiDXVzAN9jEy/gRDxgTZVEWZbHQFr52eFEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVH2DwUHRWDj5ObbAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(\"result/test-image-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAa1JREFUaAW9wb+LznEAB/CXeg8Gu43BcElRN7hsymq2GcVtKPPJfPsNzsTmDzArBuVHbCRRwh9gkeEx3HA93fN8nu9der9ememKsiiLsiiLsiiLsiiLsiiLsiiLsiiLsjiCa3hq3w5umSbKoizK4hAeYMtBm9jEG6wbi7Ioi7KY6Dm2jF3FD2NRFmVRFhNdttgMN7BrmiiLsiiLCdbMO48PmNnzELv4iVfYsFyURVmUxQSfzHtvuRfYsFyURVmUxQrb5s0sto63+GwsyqIsymKFe1b7g7f2PDMWZVEWZfEfXLLvm7Eoi7Ioi4FH5l100He8M+8j1iwWZVEWZTGwbd4VB7120G/LRVmURVkMfDfvtn1fcMZixy0XZVEWZTFwAS/tO4lN7Bj7hXMWi7Ioi7IYOIuX5u1YbcNyURZlURYDD7Hr8E5YLsqiLMpi4BhO4Lf/J8qiLMpiYGbPdTwxzVdjURZlURYTPMY67lrttLEoi7Ioi4nu4A6OWW5mtSiLsiiLQ5rZcx9/cROnTBdlURZlcUT3HU2URVmURVmURVmURVmURVmURVmURVmU/QOthjTZdSsISAAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, adjoint(::Matrix{Float64})) with eltype Gray{Float64}:\n",
       " Gray{Float64}(3.61377)  Gray{Float64}(3.63261)  …  Gray{Float64}(3.62353)\n",
       " Gray{Float64}(3.61298)  Gray{Float64}(3.61978)     Gray{Float64}(3.62402)\n",
       " Gray{Float64}(3.61771)  Gray{Float64}(3.61787)     Gray{Float64}(3.62817)\n",
       " Gray{Float64}(3.60722)  Gray{Float64}(3.63069)     Gray{Float64}(3.61253)\n",
       " Gray{Float64}(3.62484)  Gray{Float64}(3.62463)     Gray{Float64}(3.62251)\n",
       " Gray{Float64}(3.61507)  Gray{Float64}(3.62467)  …  Gray{Float64}(3.62858)\n",
       " Gray{Float64}(3.61851)  Gray{Float64}(3.62253)     Gray{Float64}(3.62237)\n",
       " Gray{Float64}(3.61998)  Gray{Float64}(3.63672)     Gray{Float64}(3.61476)\n",
       " Gray{Float64}(3.61468)  Gray{Float64}(3.61064)     Gray{Float64}(3.58488)\n",
       " Gray{Float64}(3.61703)  Gray{Float64}(3.62715)     Gray{Float64}(3.61299)\n",
       " Gray{Float64}(3.62538)  Gray{Float64}(3.62868)  …  Gray{Float64}(3.62281)\n",
       " Gray{Float64}(3.62043)  Gray{Float64}(3.61401)     Gray{Float64}(3.60849)\n",
       " Gray{Float64}(3.62445)  Gray{Float64}(3.58814)     Gray{Float64}(3.60328)\n",
       " ⋮                                               ⋱  \n",
       " Gray{Float64}(3.61992)  Gray{Float64}(3.61934)     Gray{Float64}(3.61719)\n",
       " Gray{Float64}(3.62579)  Gray{Float64}(3.63025)     Gray{Float64}(3.61393)\n",
       " Gray{Float64}(3.60664)  Gray{Float64}(3.62093)     Gray{Float64}(3.59467)\n",
       " Gray{Float64}(3.6171)   Gray{Float64}(3.61242)     Gray{Float64}(3.61497)\n",
       " Gray{Float64}(3.61426)  Gray{Float64}(3.62505)  …  Gray{Float64}(3.61471)\n",
       " Gray{Float64}(3.61833)  Gray{Float64}(3.62344)     Gray{Float64}(3.62596)\n",
       " Gray{Float64}(3.62075)  Gray{Float64}(3.61638)     Gray{Float64}(3.62329)\n",
       " Gray{Float64}(3.62094)  Gray{Float64}(3.61533)     Gray{Float64}(3.62058)\n",
       " Gray{Float64}(3.62119)  Gray{Float64}(3.62207)     Gray{Float64}(3.61352)\n",
       " Gray{Float64}(3.62375)  Gray{Float64}(3.62595)  …  Gray{Float64}(3.61468)\n",
       " Gray{Float64}(3.6234)   Gray{Float64}(3.60627)     Gray{Float64}(3.62849)\n",
       " Gray{Float64}(3.61448)  Gray{Float64}(3.61555)     Gray{Float64}(3.60484)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, reshape(decoder(randn(20)), 28,28)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92d703b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp.(decoder(randn(20)), 0 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b44c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
