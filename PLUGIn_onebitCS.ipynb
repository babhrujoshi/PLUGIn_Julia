{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux: chunk\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST\n",
    "using LinearAlgebra\n",
    "using MLDatasets\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLUGIn_onebitCS (generic function with 2 methods)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function PLUGIn_onebitCS(G, y, A, max_iter, stepsize, tolerance,lambda, out_toggle)\n",
    "    \n",
    "    (_, z_dim) = size(Flux.params(G[1])[1]);\n",
    "    (m, _) = size(A)\n",
    "    W = I(z_dim)\n",
    "  \n",
    "    #normalize the weights of the network\n",
    "    for i in 1:length(G)\n",
    "        _, s, _ = svd(Flux.params(G[i])[1])\n",
    "        W = Flux.params(G[i])[1] * W /s[1]\n",
    "    end\n",
    "  \n",
    "    z = randn(z_dim)\n",
    "    iter = 1\n",
    "    succ_error = 1\n",
    "  \n",
    "    while iter <= max_iter && succ_error > tolerance\n",
    "      \n",
    "      # d gives the PLUGIn direction\n",
    "      # d = ( A * G(z) - y .* abs.(A * G(z)) )\n",
    "      d = ( sign.(A * G(z)) - y )\n",
    "      d = W'*A'* d\n",
    "\n",
    "      # d = W'*G(z) - lambda *W'*A'*y/m\n",
    "      z -= stepsize * d\n",
    "      succ_error = norm(stepsize * d)\n",
    "      if iter % out_toggle == 0  \n",
    "          println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "      end\n",
    "      iter += 1\n",
    "    end\n",
    "    println(\"====> In quasi-gradient: Iteration: $iter Successive error: $succ_error\")\n",
    "  \n",
    "    return z\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> In quasi-gradient: Iteration: 1000 Successive error: 0.006830297176155472\n",
      "====> In quasi-gradient: Iteration: 2000 Successive error: 0.0038048801707020008\n",
      "====> In quasi-gradient: Iteration: 3000 Successive error: 0.00271062180622516\n",
      "====> In quasi-gradient: Iteration: 4000 Successive error: 0.0082761849669763\n",
      "====> In quasi-gradient: Iteration: 5000 Successive error: 0.008892733204487593\n",
      "====> In quasi-gradient: Iteration: 6000 Successive error: 0.00908612830493478\n",
      "====> In quasi-gradient: Iteration: 7000 Successive error: 0.0033661705918312606\n",
      "====> In quasi-gradient: Iteration: 7453 Successive error: 3.067225334389885e-15\n",
      "recovery error: 3.5396289516830904e-5, reconstruction error: 14.466736641511517\n"
     ]
    }
   ],
   "source": [
    "#setup a synthetic problem\n",
    "G = Chain(\n",
    "    Dense(5, 75, relu, bias = false; initW =(out,in) ->  randn(75, 5)/sqrt(75)),\n",
    "    Dense(75, 75, relu, bias = false; initW =(out,in) -> randn(75, 75)/sqrt(75)),\n",
    "    Dense(75, 150, relu, bias = false; initW =(out,in) -> randn(150, 75)/sqrt(150))\n",
    ")\n",
    "\n",
    "\n",
    "z = randn(5)\n",
    "m = 100000; A = randn(m, 150)/sqrt(m)\n",
    "y = sign.(A*G(z)) + 1e-14 * randn(m)\n",
    "\n",
    "stepsize = 1\n",
    "tolerance = 1e-14\n",
    "max_iter = 10000\n",
    "out_toggle = 1000\n",
    "lambda = 100\n",
    "z_rec = PLUGIn_onebitCS(G,y,A, max_iter, stepsize, tolerance, lambda, out_toggle)\n",
    "recov_error = norm(z/norm(z) - z_rec/norm(z_rec))\n",
    "recon_error = norm(G(z) - G(z_rec))\n",
    "println(\"recovery error: $recov_error, reconstruction error: $recon_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> In quasi-gradient: Iteration: 1000 Successive error: 5.186242623879012e-5\n",
      "recovery error: 0.05487163727428996, reconstruction error: 0.22544613623562687\n"
     ]
    }
   ],
   "source": [
    "#using Zygote to solve ERM for a synthetic problem\n",
    "\n",
    "\n",
    "G = Chain(\n",
    "    Dense(5, 75, relu, bias = false; initW =(out,in) ->  randn(75, 5)/sqrt(75)),\n",
    "    Dense(75, 75, relu, bias = false; initW =(out,in) -> randn(75, 75)/sqrt(75)),\n",
    "    Dense(75, 150, relu, bias = false; initW =(out,in) -> randn(150, 75)/sqrt(150))\n",
    ")\n",
    "\n",
    "\n",
    "z = randn(5)\n",
    "m = 5000; A = randn(m, 150)/sqrt(m)\n",
    "y = sign.(A*G(z)) + 1e-14 * randn(m)\n",
    "\n",
    "stepsize = .1\n",
    "tolerance = 1e-7\n",
    "max_iter = 1000\n",
    "out_toggle = 1000\n",
    "lambda = 10\n",
    "\n",
    "z_rec = randn(5)\n",
    "\n",
    "\n",
    "for i in 1:max_iter\n",
    "\n",
    "    d = gradient(z_rec -> norm(G(z_rec),2)^2 - 2*lambda * y'*(A * G(z_rec))/m, z_rec)[1]\n",
    "    z_rec -= stepsize * d\n",
    "    succ_error = norm(stepsize * d)\n",
    "    if i % out_toggle == 0  \n",
    "        println(\"====> In quasi-gradient: Iteration: $i Successive error: $succ_error\")\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# z_rec = PLUGIn_onebitCS(G,y,A, max_iter, stepsize, tolerance, out_toggle)\n",
    "recov_error = norm(z/norm(z) - z_rec/norm(z_rec))\n",
    "recon_error = norm(G(z) - G(z_rec))\n",
    "println(\"recovery error: $recov_error, reconstruction error: $recon_error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
