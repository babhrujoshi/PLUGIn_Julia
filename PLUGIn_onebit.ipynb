{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using JLD.@load in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux: chunk\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST\n",
    "using LinearAlgebra\n",
    "using MLDatasets\n",
    "using Plots\n",
    "using JLD\n",
    "using Statistics\n",
    "using LaTeXStrings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of recovering $x\\in\\mathbb{R}^n$ from noisy signed compressive measurements of the form\n",
    "\n",
    "$$y = \\text{sign}(Ax) + \\epsilon, $$\n",
    "\n",
    "where $\\epsilon\\in\\mathbb{R}^n$ is noise and $A \\in \\mathbb{R}^{m\\times n}$ is a known sensing matrix. We assume the unknown signal $x$ lives in the range of known a generative model $G:\\mathbb{R}^k \\rightarrow \\mathbb{R}^n$, i.e. $x = G(z)$ for some $z \\in \\mathbb{R}^k$. We assume the generative model $G$ is  fully-connected feedforward network of the form \n",
    "\n",
    "$$ G(x) = \\sigma_d(A_d\\sigma_{d-1}(A_{d-1} \\cdots \\sigma_1(A_1 z)\\cdots)),$$\n",
    "\n",
    "where $A_i \\in \\mathbb{R}^{n_i \\times n_{i-1}}$ is the weight matrix and $\\sigma_i$ is the activation function correpsonding to the $i\\text{th}$ layer of $G$. Thus, the task of recovering $x$ can be reduced to recovering the corresponding $z$ such that $G(z) = x$. \n",
    "\n",
    "\n",
    "We solve this problem using the following iterative algorithm called Partially Linearized Updates for Generative Inversion (PLUGIn)-1bit:\n",
    "\n",
    "$$x^{k+1} = x^k -\\eta A_1^{\\top}\\cdots A_d^{\\top}A^{\\top}\\left(\\text{sign}(AG(x^k)) - y \\right) .$$\n",
    "\n",
    "Here, $\\eta$ is the stepsize that depends on the weight matrices and the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLUGIN_CS (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output the plugin Iterate\n",
    "function PLUGIN_1bitCS(G, W, A, y, z, stepsize)\n",
    "    d = W'*A'* (sign.(A * G(z)) - y )\n",
    "    return z - stepsize * d\n",
    "end\n",
    "\n",
    "# output the plugin Iterate\n",
    "function PLUGIN_CS(G, W, A, y, z, stepsize)\n",
    "    d = W'*A'* (A * G(z) - y )\n",
    "    return z - stepsize * d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_weight_product (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function normalized_weight_product(G)\n",
    "    (_, z_dim) = size(Flux.params(G[1])[1]);\n",
    "    W = I(z_dim)\n",
    "    for i in 1:length(G)\n",
    "        _, s, _ = svd(Flux.params(G[i])[1])\n",
    "        W = Flux.params(G[i])[1] * W /s[1]\n",
    "    end\n",
    "    return W\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_network (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_network(net_param)\n",
    "    n_0 = net_param[1]\n",
    "    n_1 = net_param[2]\n",
    "    L = Chain(Dense(n_0, n_1, relu; initW =(out,in) ->  randn(n_1, n_0)/sqrt(n_1)))\n",
    "\n",
    "    for i in 2:length(net_param)-1\n",
    "        n_0 = net_param[i]\n",
    "        n_1 = net_param[i+1]\n",
    "        L = Chain(L, Dense(n_0, n_1, relu; initW =(out,in) ->  randn(n_1, n_0)/sqrt(n_1)))\n",
    "    end\n",
    "    return L\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLUGIN_kbitCS_estimate (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function k_quantized(z,k)\n",
    "    return round.((k-1)*z)/(k-1)\n",
    "end\n",
    "\n",
    "function scalar_quantizer(z,k,delta)\n",
    "    if  abs(z) < k*delta/2\n",
    "        z = delta * floor(z/delta) + delta/2\n",
    "    else\n",
    "        z = k*delta/2\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "\n",
    "function sigma_delta_quant(y, k, delta)\n",
    "    m = length(y)\n",
    "    u = zeros(m+1)\n",
    "    for i in 1:m\n",
    "        q = scalar_quantizer(y[i] + u[i], k, delta)\n",
    "        u[i+1] = u[i] + y[i] - q\n",
    "        y[i] = q\n",
    "    end\n",
    "    return y, u\n",
    "end\n",
    "\n",
    "\n",
    "# output the plugin Iterate\n",
    "function PLUGIN_kbitCS_estimate(A, G, W, y, z, k, stepsize)\n",
    "    d = W'*A'* (k_quantized(A * G(z), k) - y )\n",
    "    return z - stepsize * d\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first experiment, we want to examine the convergence rate of the PLUGIn-bit algorithm as a function of the number of measurement. Define the recovery error  as:\n",
    "$$\\text{recovery error, $\\delta$} := \\left\\| \\tfrac{x^{\\natural}}{\\|x^\\natural\\|} - \\tfrac{x^*}{\\|x^*\\|} \\right\\|,$$\n",
    "where $x^\\natural$ is the recovered estimate of ground truth $x^*$. We hope to see a error decay as $\\delta \\sim \\tfrac{1}{m^\\alpha}$ for some $\\alpha \\in (0,1)$.\n",
    "\n",
    "\n",
    "The following code segment is used to generate the relationship betwen $\\delta$ and $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_param = [5, 200, 750]\n",
    "x_dim  = net_param[length(net_param)]\n",
    "z_dim = net_param[1]\n",
    "\n",
    "G = create_network(net_param)\n",
    "    \n",
    "stepsize = 1\n",
    "max_iter = 2000\n",
    "tolerance = 1e-7\n",
    "\n",
    "W = normalized_weight_product(G)\n",
    "m_list = 750:1000:50000\n",
    "trials = 10\n",
    "recov_error_matrix = zeros(length(m_list))\n",
    "\n",
    "for trial in 1:trials\n",
    "    recov_error = []\n",
    "    z = randn(z_dim)\n",
    "\n",
    "    for m in m_list\n",
    "        A = randn(m, x_dim)/sqrt(m)\n",
    "        y = sign.(A*G(z))\n",
    "        z_est = zeros(z_dim)\n",
    "        iter = 1\n",
    "        succ_error = 1\n",
    "\n",
    "        while iter <= max_iter && succ_error > tolerance\n",
    "            z_old = z_est\n",
    "            z_est = PLUGIN_1bitCS(G, W, A, y, z_est, stepsize)\n",
    "            succ_error = norm(z_old - z_est, 2)\n",
    "            iter += 1\n",
    "        end\n",
    "        push!(recov_error, norm(z/norm(z) - z_est/norm(z_est)))\n",
    "    end\n",
    "    recov_error_matrix = hcat(recov_error_matrix, recov_error)\n",
    "\n",
    "end\n",
    "\n",
    "# change the filename before running this code if you wish to save the results\n",
    "\n",
    "# M = recov_error_matrix[:,2:end]\n",
    "# save(\"result/error_1.jld\", \"error\", M, \"measurement\", m_list, \"trials\", trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
